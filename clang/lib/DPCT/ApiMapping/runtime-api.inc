REGISTER_ENTRY(
"cudaDeviceGetAttribute",
"CUDA API:\n"
"    cudaError_t cudaDeviceGetAttribute(int* value, cudaDeviceAttr attr, int device)\n"
"Migrates to helper function:\n"
"    device_ext dpct::dev_mgr::get_device(unsigned int id)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      int clockRate = 0;\n"
"      int dev_id;\n"
"      cudaGetDevice(&dev_id);\n"
"      cudaDeviceGetAttribute(&clockRate, cudaDevAttrClockRate, dev_id);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      int clockRate = 0;\n"
"      int dev_id;\n"
"      dev_id = dpct::dev_mgr::instance().current_device_id();\n"
"      clockRate = \n"
"          dpct::dev_mgr::instance().get_device(dev_id).get_max_clock_frequency();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaDeviceGetLimit",
"CUDA API:\n"
"    cudaError_t cudaDeviceGetLimit(size_t* pValue, cudaLimit limit)\n"
"Migrates to SYCL API:\n"
"    =\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      size_t *pValue;\n"
"      cudaLimit limit;\n"
"      cudaDeviceGetLimit(pValue, limit);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      size_t *pValue;\n"
"      cudaLimit limit;\n"
"      /*\n"
"      DPCT1029:0: SYCL currently does not support getting device resource limits.\n"
"      The output parameter(s) are set to 0.\n"
"      */\n"
"      *pValue = 0;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaDeviceReset",
"CUDA API:\n"
"    cudaError_t cudaDeviceReset(void)\n"
"Migrates to helper function:\n"
"    void dpct::device_ext::reset()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaDeviceReset();\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::get_current_device().reset();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaDeviceSynchronize",
"CUDA API:\n"
"    cudaError_t cudaDeviceSynchronize(void)\n"
"Migrates to helper function:\n"
"    void dpct::device_ext::queues_wait_and_throw()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaDeviceSynchronize();\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::get_current_device().queues_wait_and_throw();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaGetDevice",
"CUDA API:\n"
"    cudaError_t cudaGetDevice(int* device)\n"
"Migrates to helper function:\n"
"    unsigned int dpct::dev_mgr::current_device_id()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      int dev_id;\n"
"      cudaGetDevice(&dev_id);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      int dev_id;\n"
"      dev_id = dpct::dev_mgr::instance().current_device_id();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaGetDeviceCount",
"CUDA API:\n"
"    cudaError_t cudaGetDeviceCount(int* count)\n"
"Migrates to helper function:\n"
"    unsigned int dpct::dev_mgr::device_count()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      int deviceCount = 0;\n"
"      cudaGetDeviceCount(&deviceCount);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      int deviceCount = 0;\n"
"      deviceCount = dpct::dev_mgr::instance().device_count();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaGetDeviceProperties",
"CUDA API:\n"
"    cudaError_t cudaGetDeviceProperties(cudaDeviceProp* prop, int device)\n"
"Migrates to helper function:\n"
"    void dpct::device_ext::get_device_info(device_info &out)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaDeviceProp deviceProp;\n"
"      cudaGetDeviceProperties(&deviceProp, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::device_info deviceProp;\n"
"      dpct::dev_mgr::instance().get_device(0).get_device_info(deviceProp);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaSetDevice",
"CUDA API:\n"
"    cudaError_t cudaSetDevice(int device)\n"
"Migrates to helper function:\n"
"    unsigned int dpct::select_device(unsigned int id)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaSetDevice(0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      /*\n"
"      DPCT1093:0: The \"0\" may not be the best XPU device. Adjust the selected device\n"
"      if needed.\n"
"      */\n"
"      dpct::select_device(0);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaThreadExit",
"CUDA API:\n"
"    cudaError_t cudaThreadExit(void)\n"
"Migrates to helper function:\n"
"    void dpct::device_ext::reset()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaThreadExit();\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::get_current_device().reset();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaThreadSynchronize",
"CUDA API:\n"
"    cudaError_t cudaThreadSynchronize(void)\n"
"Migrates to helper function:\n"
"    void dpct::device_ext::queues_wait_and_throw()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaThreadSynchronize();\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::get_current_device().queues_wait_and_throw();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamAddCallback",
"CUDA API:\n"
"    cudaError_t cudaStreamAddCallback(cudaStream_t stream, cudaStreamCallback_t callback, void* userData, unsigned int flags)\n"
"Migrates to SYCL API:\n"
"    future<__async_result_of<_Fn, _Args...>> std::async(_Fn&& __fn, _Args&&... __args)\n"
"For example, the CUDA code:\n"
"    void f(cudaStream_t stream, cudaError_t status, void *userData) {}\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"      char str[256];\n"
"      cudaStreamAddCallback(s, f, str, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    #include <future>\n"
"    void f(dpct::queue_ptr stream, int status, void *userData) {}\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      s = dpct::get_current_device().create_queue();\n"
"      char str[256];\n"
"      std::async([&]() { s->wait(); f(s, 0, str); });\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamCreate",
"CUDA API:\n"
"    cudaError_t cudaStreamCreate(cudaStream_t* pStream)\n"
"Migrates to helper function:\n"
"    sycl::queue *dpct::device_ext::create_queue()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      s = dpct::get_current_device().create_queue();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamCreateWithFlags",
"CUDA API:\n"
"    cudaError_t cudaStreamCreateWithFlags(cudaStream_t* pStream, unsigned int flags)\n"
"Migrates to helper function:\n"
"    sycl::queue *dpct::device_ext::create_queue()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreateWithFlags(&s, cudaStreamDefault);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      /*\n"
"      DPCT1025:0: The SYCL queue is created ignoring the flag and priority options.\n"
"      */\n"
"      s = dpct::get_current_device().create_queue();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamCreateWithPriority",
"CUDA API:\n"
"    cudaError_t cudaStreamCreateWithPriority(cudaStream_t* pStream, unsigned int flags, int priority)\n"
"Migrates to helper function:\n"
"    sycl::queue *dpct::device_ext::create_queue()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreateWithPriority(&s, cudaStreamDefault);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      /*\n"
"      DPCT1025:0: The SYCL queue is created ignoring the flag and priority options.\n"
"      */\n"
"      s = dpct::get_current_device().create_queue();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamDestroy",
"CUDA API:\n"
"    cudaError_t cudaStreamDestroy(cudaStream_t stream)\n"
"Migrates to helper function:\n"
"    void *dpct::device_ext::destroy_queue(sycl::queue *&queue)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"      cudaStreamDestroy(s);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      dpct::queue_ptr s;\n"
"      s = dev_ct1.create_queue();\n"
"      dev_ct1.destroy_queue(s);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamGetFlags",
"CUDA API:\n"
"    cudaError_t cudaStreamGetFlags(cudaStream_t hStream, unsigned int* flags)\n"
"Migrates to SYCL API:\n"
"    =\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"      unsigned int flags = 0;\n"
"      cudaStreamGetFlags(s, &flags);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      s = dpct::get_current_device().create_queue();\n"
"      unsigned int flags = 0;\n"
"      /*\n"
"      DPCT1014:0: The flag and priority options are not supported for SYCL queues.\n"
"      The output parameter(s) are set to 0.\n"
"      */\n"
"      *(&flags) = 0;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamGetPriority",
"CUDA API:\n"
"    cudaError_t cudaStreamGetPriority(cudaStream_t hStream, int* priority)\n"
"Migrates to SYCL API:\n"
"    =\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"      int priority;\n"
"      cudaStreamGetPriority(s, &priority);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      s = dpct::get_current_device().create_queue();\n"
"      unsigned int flags = 0;\n"
"      /*\n"
"      DPCT1014:0: The flag and priority options are not supported for SYCL queues.\n"
"      The output parameter(s) are set to 0.\n"
"      */\n"
"      *(&flags) = 0;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamSynchronize",
"CUDA API:\n"
"    cudaError_t cudaStreamSynchronize(cudaStream_t stream)\n"
"Migrates to SYCL API:\n"
"    void sycl::queue::wait()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"      cudaStreamSynchronize(s);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      s = dpct::get_current_device().create_queue();\n"
"      s->wait();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaStreamWaitEvent",
"CUDA API:\n"
"    cudaError_t cudaStreamWaitEvent(cudaStream_t stream, cudaEvent_t event, unsigned int flags = 0)\n"
"Migrates to SYCL API:\n"
"    event sycl::queue::ext_oneapi_submit_barrier(const std::vector<event> &WaitList _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaStream_t s;\n"
"      cudaStreamCreate(&s);\n"
"      cudaEvent_t e;\n"
"      cudaEventCreate(&e);\n"
"      cudaStreamWaitEvent(s, e, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::queue_ptr s;\n"
"      s = dpct::get_current_device().create_queue();\n"
"      dpct::event_ptr e;\n"
"      e = new sycl::event();\n"
"      s->ext_oneapi_submit_barrier({*e});\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaEventCreate",
"CUDA API:\n"
"    cudaError_t cudaEventCreate(cudaEvent_t* event)\n"
"Migrates to SYCL API:\n"
"    sycl::event::event()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaEvent_t e;\n"
"      cudaEventCreate(&e);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::event_ptr e;\n"
"      e = new sycl::event();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaEventCreateWithFlags",
"CUDA API:\n"
"    cudaError_t cudaEventCreateWithFlags(cudaEvent_t* event, unsigned int flags)\n"
"Migrates to SYCL API:\n"
"    sycl::event::event()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaEvent_t e;\n"
"      cudaEventCreateWithFlags(&e, cudaEventDefault);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::event_ptr e;\n"
"      e = new sycl::event();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaEventDestroy",
"CUDA API:\n"
"    cudaError_t cudaEventDestroy(cudaEvent_t event)\n"
"Migrates to helper function:\n"
"    void dpct::destroy_event(event_ptr event)\n"
"    **Parameters**\n"
"    * event: Event pointer to the sycl::event address\n"
"    Destroy the event pointed memory.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaEvent_t e;\n"
"      cudaEventCreate(&e);\n"
"      cudaEventDestroy(e);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::event_ptr e;\n"
"      e = new sycl::event();\n"
"      dpct::destroy_event(e);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaEventQuery",
"CUDA API:\n"
"    cudaError_t cudaEventQuery(cudaEvent_t event)\n"
"Migrates to SYCL API:\n"
"    detail::is_event_info_desc<Param>::return_type sycl::event::get_info()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaEvent_t e;\n"
"      cudaEventCreate(&e);\n"
"      cudaEventQuery(e);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::event_ptr e;\n"
"      e = new sycl::event();\n"
"      (int)e->get_info<sycl::info::event::command_execution_status>();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaEventRecord",
"CUDA API:\n"
"    cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream = 0)\n"
"Migrates to SYCL API:\n"
"    time_point std::chrono::steady_clock::now()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaEvent_t e;\n"
"      cudaEventCreate(&e);\n"
"      cudaEventRecord(e, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    #include <chrono>\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      sycl::queue &q_ct1 = dev_ct1.default_queue();\n"
"      dpct::event_ptr e;\n"
"      std::chrono::time_point<std::chrono::steady_clock> e_ct1;\n"
"      e = new sycl::event();\n"
"      /*\n"
"      DPCT1012:0: Detected kernel execution time measurement pattern and generated\n"
"      an initial code for time measurements in SYCL. You can change the way time is\n"
"      measured depending on your goals.\n"
"      */\n"
"      e_ct1 = std::chrono::steady_clock::now();\n"
"      *e = q_ct1.ext_oneapi_submit_barrier();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaEventSynchronize",
"CUDA API:\n"
"    cudaError_t cudaEventSynchronize(cudaEvent_t event)\n"
"Migrates to SYCL API:\n"
"    void sycl::event::wait_and_throw()\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaEvent_t e;\n"
"      cudaEventCreate(&e);\n"
"      cudaEventSynchronize(e);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::event_ptr e;\n"
"      e = new sycl::event();\n"
"      e->wait_and_throw();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaFuncGetAttributes",
"CUDA API:\n"
"    cudaError_t cudaFuncGetAttributes(cudaFuncAttributes* attr, const void* func)\n"
"Migrates to helper function:\n"
"    void dpct::get_kernel_function_info(kernel_function_info *kernel_info, const void *function)\n"
"For example, the CUDA code:\n"
"    __global__ void f() {}\n"
"    int main() {\n"
"      cudaFuncAttributes attr;\n"
"      cudaFuncGetAttributes(&attr, f);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    void f() {}\n"
"    int main() {\n"
"      dpct::kernel_function_info attr;\n"
"      (dpct::get_kernel_function_info(&attr, (const void *)f), 0);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaLaunchCooperativeKernel",
"CUDA API:\n"
"    cudaError_t cudaLaunchCooperativeKernel(const void* func, dim3 gridDim, dim3 blockDim, void** args, size_t sharedMem, cudaStream_t stream)\n"
"Migrates to SYCL API:\n"
"    event sycl::queue::parallel_for(range<1> Range, RestT &&...Rest)\n"
"    event sycl::queue::parallel_for(range<2> Range, RestT &&...Rest)\n"
"    event sycl::queue::parallel_for(range<3> Range, RestT &&...Rest)\n"
"For example, the CUDA code:\n"
"    __global__ void f() {}\n"
"    int main() {\n"
"      void *args[0];\n"
"      cudaLaunchCooperativeKernel((void *)&f, dim3(16), dim3(16), args, 0, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    void f() {}\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      sycl::queue &q_ct1 = dev_ct1.default_queue();\n"
"      void *args[0];\n"
"      q_ct1.parallel_for(\n"
"          sycl::nd_range<3>(sycl::range<3>(1, 1, 16) * sycl::range<3>(1, 1, 16),\n"
"                            sycl::range<3>(1, 1, 16)),\n"
"          [=](sycl::nd_item<3> item_ct1) {\n"
"            f();\n"
"          });\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaLaunchKernel",
"CUDA API:\n"
"    cudaError_t cudaLaunchKernel(const void* func, dim3 gridDim, dim3 blockDim, void** args, size_t sharedMem, cudaStream_t stream)\n"
"Migrates to SYCL API:\n"
"    event sycl::queue::parallel_for(range<1> Range, RestT &&...Rest)\n"
"    event sycl::queue::parallel_for(range<2> Range, RestT &&...Rest)\n"
"    event sycl::queue::parallel_for(range<3> Range, RestT &&...Rest)\n"
"For example, the CUDA code:\n"
"    __global__ void f() {}\n"
"    int main() {\n"
"      void *args[0];\n"
"      cudaLaunchKernel((void *)&f, dim3(16), dim3(16), args, 0, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    void f() {}\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      sycl::queue &q_ct1 = dev_ct1.default_queue();\n"
"      void *args[0];\n"
"      q_ct1.parallel_for(\n"
"          sycl::nd_range<3>(sycl::range<3>(1, 1, 16) * sycl::range<3>(1, 1, 16),\n"
"                            sycl::range<3>(1, 1, 16)),\n"
"          [=](sycl::nd_item<3> item_ct1) {\n"
"            f();\n"
"          });\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaArrayGetInfo",
"CUDA API:\n"
"    cudaError_t cudaArrayGetInfo(cudaChannelFormatDesc* desc, cudaExtent* extent, unsigned int* flags, cudaArray_t array)\n"
"Migrates to helper function:\n"
"    image_channel dpct::image_matrix::get_channel()\n"
"    Get channel info.\n"
"    sycl::range<3> dpct::image_matrix::get_range()\n"
"    Get range of the image.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaChannelFormatDesc desc;\n"
"      cudaExtent extent;\n"
"      unsigned int flags;\n"
"      cudaArray_t array;\n"
"      cudaChannelFormatDesc channel;\n"
"      cudaMallocArray(&array, &channel, 1, 1);\n"
"      cudaArrayGetInfo(&desc, &extent, &flags, array);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::image_channel desc;\n"
"      sycl::range<3> extent;\n"
"      unsigned int flags;\n"
"      dpct::image_matrix_p array;\n"
"      dpct::image_channel channel;\n"
"      array = new dpct::image_matrix(channel, sycl::range<2>(1, 1));\n"
"      desc = array->get_channel();\n"
"      extent = array->get_range();\n"
"      flags = 0;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaFree",
"CUDA API:\n"
"    cudaError_t cudaFree(void* devPtr)\n"
"Migrates to SYCL API:\n"
"    void sycl::free(void *ptr, const queue &q _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      cudaMalloc((void **)&p, sizeof(p));\n"
"      cudaFree(p);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      sycl::queue &q_ct1 = dev_ct1.default_queue();\n"
"      float *p = NULL;\n"
"      p = (float *)sycl::malloc_device(sizeof(p), q_ct1);\n"
"      sycl::free(p, q_ct1);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaFreeArray",
"CUDA API:\n"
"    cudaError_t cudaFreeArray(cudaArray_t array)\n"
"Migrates to SYCL API:\n"
"    delete\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaArray_t array;\n"
"      cudaChannelFormatDesc channel;\n"
"      cudaMallocArray(&array, &channel, 1, 1);\n"
"      cudaFreeArray(array);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::image_matrix_p array;\n"
"      dpct::image_channel channel;\n"
"      array = new dpct::image_matrix(channel, sycl::range<2>(1, 1));\n"
"      delete array;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaFreeHost",
"CUDA API:\n"
"    cudaError_t cudaFreeHost(void* ptr)\n"
"Migrates to SYCL API:\n"
"    void sycl::free(void *ptr, const queue &q _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      cudaMalloc((void **)&p, sizeof(p));\n"
"      cudaFreeHost(p);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      sycl::queue &q_ct1 = dev_ct1.default_queue();\n"
"      float *p = NULL;\n"
"      p = (float *)sycl::malloc_device(sizeof(p), q_ct1);\n"
"      sycl::free(p, q_ct1);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaGetSymbolAddress",
"CUDA API:\n"
"    cudaError_t cudaGetSymbolAddress(void** devPtr, const void* symbol)\n"
"Migrates to helper function:\n"
"    value_t *dpct::detail::device_memory::get_ptr()\n"
"For example, the CUDA code:\n"
"    static __device__ float arr[1];\n"
"    int main() {\n"
"      void *p_addr;\n"
"      cudaGetSymbolAddress(&p_addr, arr);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    static dpct::global_memory<float, 1> arr(1);\n"
"    int main() {\n"
"      void *p_addr;\n"
"      *(&p_addr) = arr.get_ptr();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaGetSymbolSize",
"CUDA API:\n"
"    cudaError_t cudaGetSymbolSize(size_t* size, const void* symbol)\n"
"Migrates to helper function:\n"
"    size_t dpct::detail::device_memory::get_size()\n"
"    Get the device memory object size in bytes.\n"
"For example, the CUDA code:\n"
"    static __device__ float arr[1];\n"
"    int main() {\n"
"      size_t size2;\n"
"      cudaGetSymbolSize(&size2, arr);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    static dpct::global_memory<float, 1> arr(1);\n"
"    int main() {\n"
"      size_t size2;\n"
"      size2 = arr.get_size();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaHostAlloc",
"CUDA API:\n"
"    cudaError_t cudaHostAlloc(void** pHost, size_t size, unsigned int flags)\n"
"Migrates to SYCL API:\n"
"    void *sycl::malloc_host(size_t size, const queue &q _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      cudaHostAlloc((void **)&p, sizeof(p), cudaHostAllocDefault);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      /*\n"
"      DPCT1048:0: The original value cudaHostAllocDefault is not meaningful in the\n"
"      migrated code and was removed or replaced with 0. You may need to check the\n"
"      migrated code.\n"
"      */\n"
"      p = (float *)sycl::malloc_host(sizeof(p), dpct::get_default_queue());\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaHostGetDevicePointer",
"CUDA API:\n"
"    cudaError_t cudaHostGetDevicePointer(void** pDevice, void* pHost, unsigned int flags)\n"
"Migrates to SYCL API:\n"
"    =\n"
"For example, the CUDA code:\n"
"    static __device__ float arr[1];\n"
"    int main() {\n"
"      void *p_addr;\n"
"      cudaHostGetDevicePointer(&p_addr, arr, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    static dpct::global_memory<float, 1> arr(1);\n"
"    int main() {\n"
"      void *p_addr;\n"
"      p_addr = (char *)arr;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaHostGetFlags",
"CUDA API:\n"
"    cudaError_t cudaHostGetFlags(unsigned int* pFlags, void* pHost)\n"
"Migrates to SYCL API:\n"
"    =\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      int host;\n"
"      unsigned int flags;\n"
"      cudaHostGetFlags(&flags, &host);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      int host;\n"
"      unsigned int flags;\n"
"      flags = 0;\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMalloc",
"CUDA API:\n"
"    cudaError_t cudaMalloc(void** devPtr, size_t size)\n"
"Migrates to SYCL API:\n"
"    void *sycl::malloc_device(size_t size, const queue &q _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      cudaMalloc((void **)&p, sizeof(p));\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      p = (float *)sycl::malloc_device(sizeof(p), dpct::get_default_queue());\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMalloc3D",
"CUDA API:\n"
"    cudaError_t cudaMalloc3D(cudaPitchedPtr* pitchedDevPtr, cudaExtent extent)\n"
"Migrates to helper function:\n"
"    pitched_data dpct::dpct_malloc(sycl::range<3> size, sycl::queue &q = get_default_queue())\n"
"    **Parameters**\n"
"    * size: Size of the memory block, in bytes.\n"
"    * q: Queue to execute the allocate task.\n"
"    Returns a pitched_data object, which stores the allocated memory block information for a 3D array on the device.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaPitchedPtr p_A;\n"
"      cudaExtent extent = make_cudaExtent(1, 1, 1);\n"
"      cudaMalloc3D(&p_A, extent);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::pitched_data p_A;\n"
"      sycl::range<3> extent = sycl::range<3>(1, 1, 1);\n"
"      p_A = dpct::dpct_malloc(extent);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMalloc3DArray",
"CUDA API:\n"
"    cudaError_t cudaMalloc3DArray(cudaArray_t* array, const cudaChannelFormatDesc* desc, cudaExtent extent, unsigned int  flags = 0)\n"
"Migrates to helper function:\n"
"    dpct::image_matrix(image_channel channel, sycl::range<dimensions> range)\n"
"    Constructor with channel info and dimension size info.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaArray_t a;\n"
"      cudaChannelFormatDesc channel;\n"
"      cudaExtent extent = make_cudaExtent(1, 1, 1);\n"
"      cudaMalloc3DArray(&a, &channel, extent);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::image_matrix_p a;\n"
"      dpct::image_channel channel;\n"
"      sycl::range<3> extent = sycl::range<3>(1, 1, 1);\n"
"      a = new dpct::image_matrix(channel, extent);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMallocArray",
"CUDA API:\n"
"    cudaError_t cudaMallocArray(cudaArray_t* array, const cudaChannelFormatDesc* desc, size_t width, size_t height = 0, unsigned int flags = 0)\n"
"Migrates to helper function:\n"
"    dpct::image_matrix(image_channel channel, sycl::range<dimensions> range)\n"
"    Constructor with channel info and dimension size info.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      cudaArray_t a;\n"
"      cudaChannelFormatDesc channel;\n"
"      cudaMallocArray(&a, &channel, 1, 1, 1);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::image_matrix_p a;\n"
"      dpct::image_channel channel;\n"
"      a = new dpct::image_matrix(channel, sycl::range<2>(1, 1));\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMallocHost",
"CUDA API:\n"
"    cudaError_t cudaMallocHost(void** ptr, size_t size)\n"
"Migrates to SYCL API:\n"
"    void *sycl::malloc_host(size_t size, const queue &q _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      cudaMallocHost((void **)&p, sizeof(p));\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      p = (float *)sycl::malloc_host(sizeof(p), dpct::get_default_queue());\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMallocManaged",
"CUDA API:\n"
"    cudaError_t cudaMallocManaged(void** devPtr, size_t size, unsigned int flags = cudaMemAttachGlobal)\n"
"Migrates to SYCL API:\n"
"    void *sycl::malloc_shared(size_t size, const queue &q _CODELOCPARAM(&CodeLoc))\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      cudaMallocManaged((void **)&p, sizeof(p));\n"
"    }\n"
"Is migrated to SYCL code:\n"
"        #include <sycl/sycl.hpp>\n"
"        #include <dpct/dpct.hpp>\n"
"        int main() {\n"
"          float *p = NULL;\n"
"          p = (float *)sycl::malloc_shared(sizeof(p), dpct::get_default_queue());\n"
"        }\n"
)
REGISTER_ENTRY(
"cudaMallocPitch",
"CUDA API:\n"
"    cudaError_t cudaMallocPitch(void** devPtr, size_t* pitch, size_t width, size_t height)\n"
"Migrates to helper function:\n"
"    pitched_data dpct::dpct_malloc(T num_bytes, sycl::queue &q = get_default_queue())\n"
"    **Parameters**\n"
"    * size: Size of the memory block, in bytes.\n"
"    * q: Queue to execute the allocate task.\n"
"    Returns a pitched_data object, which stores the allocated memory block information for a 3D array on the device.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      size_t size = 1;\n"
"      cudaMallocPitch((void **)&p, &size, 1, 1);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      float *p = NULL;\n"
"      size_t size = 1;\n"
"      p = (float *)dpct::dpct_malloc(size, 1, 1);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMemAdvise",
"CUDA API:\n"
"    cudaError_t cudaMemAdvise(const void* devPtr, size_t count, cudaMemoryAdvise advice, int device)\n"
"Migrates to SYCL API:\n"
"    event sycl::queue::mem_advise(const void *Ptr, size_t Length, int Advice)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      int *devPtr;\n"
"      cudaMemAdvise(devPtr, 1,  cudaMemAdviseSetReadMostly, 0);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      int *devPtr;\n"
"      /*\n"
"      DPCT1063:0: Advice parameter is device-defined and was set to 0. You may need\n"
"      to adjust it.\n"
"      */\n"
"      dpct::get_device(0).default_queue().mem_advise(devPtr, 1, 0);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMemGetInfo",
"CUDA API:\n"
"    cudaError_t cudaMemGetInfo(size_t* free, size_t* total)\n"
"Migrates to helper function:\n"
"    void dpct::device_ext::get_memory_info(size_t &free_memory, size_t &total_memory)\n"
"    **Parameters**\n"
"    * free_memory: The number of bytes of free memory on the SYCL device.\n"
"    * total_memory: The number of bytes of total memory on the SYCL device.\n"
"    Get the number of bytes of free and total memory on the SYCL device.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      size_t free, total;\n"
"      cudaMemGetInfo(&free, &total);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      size_t free, total;\n"
"      dpct::get_current_device().get_memory_info(free, total);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMemPrefetchAsync",
"CUDA API:\n"
"    cudaError_t cudaMemPrefetchAsync(const void* devPtr, size_t count, int dstDevice, cudaStream_t stream = 0)\n"
"Migrates to SYCL API:\n"
"    event sycl::queue::prefetch(const void *Ptr, size_t Count)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *devPtr = NULL;\n"
"      cudaMemPrefetchAsync(devPtr, 100, cudaMemAdviseSetReadMostly,\n"
"                           cudaStreamDefault);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      float *devPtr = NULL;\n"
"      /*\n"
"      DPCT1063:0: Advice parameter is device-defined and was set to 0. You may need\n"
"      to adjust it.\n"
"      */\n"
"      dpct::dev_mgr::instance().get_device(0).default_queue().prefetch(devPtr, 100);\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMemcpy",
"CUDA API:\n"
"    cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)\n"
"Migrates to SYCL API:\n"
"    event sycl::queue::memcpy(void *Dest, const void *Src, size_t Count)\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *h_A = NULL;\n"
"      cudaMallocHost(&h_A, sizeof(h_A));\n"
"      float *d_A = NULL;\n"
"      cudaMemcpy(d_A, h_A, sizeof(h_A), cudaMemcpyHostToDevice);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      dpct::device_ext &dev_ct1 = dpct::get_current_device();\n"
"      sycl::queue &q_ct1 = dev_ct1.default_queue();\n"
"      float *h_A = NULL;\n"
"      h_A = (float *)sycl::malloc_host(sizeof(h_A), q_ct1);\n"
"      float *d_A = NULL;\n"
"      q_ct1.memcpy(d_A, h_A, sizeof(h_A)).wait();\n"
"    }\n"
)
REGISTER_ENTRY(
"cudaMemcpy2D",
"CUDA API:\n"
"    cudaError_t cudaMemcpy2D(void* dst, size_t dpitch, const void* src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind)\n"
"Migrates to helper function:\n"
"    evoid dpct::memcpy(void *to_ptr, size_t to_pitch, const void *from_ptr, size_t from_pitch, size_t x, size_t y, memcpy_direction direction = automatic, sycl::queue &q = dpct::get_default_queue())\n"
"    **Parameters**\n"
"    * to_ptr: Pointer to destination memory address\n"
"    * to_pitch: Range of dim x in bytes of destination matrix\n"
"    * from_ptr: Pointer to source memory address\n"
"    * from_pitch: Range of dim x in bytes of source matrix\n"
"    * x: Range of dim x of matrix to be copied\n"
"    * y: Range of dim y of matrix to be copied\n"
"    * direction: Direction of the copy\n"
"    * q: Queue to execute the copy task\n"
"    Synchronously copies 2D matrix specified by x and y from the address specified by from_ptr to the\n"
"    address specified by to_ptr, while from_pitch and to_pitch are the range of dim x in bytes of the matrix\n"
"    specified by from_ptr and to_ptr. The value of direction is used to set the copy direction, it can be\n"
"    host_to_host, host_to_device, device_to_host, device_to_device or automatic. The function will\n"
"    return after the copy is completed.\n"
"For example, the CUDA code:\n"
"    int main() {\n"
"      float *h_A = NULL;\n"
"      auto size = sizeof(h_A);\n"
"      cudaMallocHost(&h_A, size);\n"
"      float *d_A = NULL;\n"
"      cudaMemcpy2D(d_A, size, h_A, size, size, size, cudaMemcpyHostToDevice);\n"
"    }\n"
"Is migrated to SYCL code:\n"
"    #include <sycl/sycl.hpp>\n"
"    #include <dpct/dpct.hpp>\n"
"    int main() {\n"
"      float *h_A = NULL;\n"
"      auto size = sizeof(h_A);\n"
"      h_A = (float *)sycl::malloc_host(size, dpct::get_default_queue());\n"
"      float *d_A = NULL;\n"
"      dpct::dpct_memcpy(d_A, size, h_A, size, size, size, dpct::host_to_device);\n"
)
